{"pageProps":{"post":{"attributes":{},"html":"<h1>Chain of Thought (CoT)</h1>\n<p>There was a study <a href=\"https://arxiv.org/pdf/2205.11916\">Large Language Models are Zero-Shot Reasoners</a> and it looked at the accuracy of LLMs with different prompts.</p>\n<p>There has been research on the phrase &quot;let&#39;s think step by step&quot; added to prompts and this study looked specifically at this &quot;zero-shot chain of thought prompt&quot; performance on a diverse set of reasoning tasks including arithmetic and logical reasoning tasks without any few shot examples.</p>\n<p>Amazingly, accuracy on the multi-arithmetic problems went from 17.7% to 78.7%.</p>\n<p>Something else amazing about this &quot;chain of thought&quot; reasoning is that the reasoning performance of the models got better as the models got larger as well.</p>\n<p>Its important to really appreciate just this simple five word addition to our prompts because let&#39;s think step by step is versatile and task-agnostic, you can use it for basically anything...code generation, math problems, complex reasoning, etc.</p>\n<p>I&#39;d highly encourage reading the paper to understand more of why this works.</p>\n<p>Here is an example of using CoT reasoning in a prompt:</p>\n<pre><code><button class=\"copy-btn\">Copy</button>Can penguins fly?\nThink through this step by step.\n</code></pre><p>For our prompt library, let&#39;s build something complex, like the ability to import and export our prompts. Since we are only saving them currently to localStorage, they are going to disappear on us, so if we build an export system to JSON, then we can download the JSON and we can import it the next time we load our prompt library, and we can just have it all back without worrying about where those files need to live or adding a database or anything like that, so let&#39;s use chain of thought prompting to build this import/export feature as our last big feature to this project.</p>\n<pre><code><button class=\"copy-btn\">Copy</button>Let&#x27;s build a complete export/import system step by step.\n\nStep 1: First, analyze what data we need to export:\n- All prompts with their metadata\n\nStep 2: Design the export JSON schema that includes:\n- Version number for future compatibility\n- Export timestamp\n- Statistics (total prompts, average rating, most used model)\n- Complete prompts array\n\nStep 3: Create the export function that:\n- Gathers all data from localStorage\n- Validates data integrity\n- Creates a blob and triggers download with timestamp\n\nStep 4: Create the import function that:\n- Reads the uploaded file\n- Validates the JSON structure and version\n- Checks for duplicate IDs\n- Merges or replaces existing data based on user choice\n\nStep 5: Add error recovery:\n- Backup existing data before import\n- Rollback on failure\n- Provide detailed error messages\n\nAdd the import and export buttons and merge conflict resolution prompts\n\nImplement this complete system with all steps. Think step by step.\n</code></pre>","markdown":"# Chain of Thought (CoT)\n\nThere was a study [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916) and it looked at the accuracy of LLMs with different prompts.\n\nThere has been research on the phrase \"let's think step by step\" added to prompts and this study looked specifically at this \"zero-shot chain of thought prompt\" performance on a diverse set of reasoning tasks including arithmetic and logical reasoning tasks without any few shot examples.\n\nAmazingly, accuracy on the multi-arithmetic problems went from 17.7% to 78.7%.\n\nSomething else amazing about this \"chain of thought\" reasoning is that the reasoning performance of the models got better as the models got larger as well.\n\nIts important to really appreciate just this simple five word addition to our prompts because let's think step by step is versatile and task-agnostic, you can use it for basically anything...code generation, math problems, complex reasoning, etc.\n\nI'd highly encourage reading the paper to understand more of why this works.\n\nHere is an example of using CoT reasoning in a prompt:\n```\nCan penguins fly?\nThink through this step by step.\n```\n\nFor our prompt library, let's build something complex, like the ability to import and export our prompts. Since we are only saving them currently to localStorage, they are going to disappear on us, so if we build an export system to JSON, then we can download the JSON and we can import it the next time we load our prompt library, and we can just have it all back without worrying about where those files need to live or adding a database or anything like that, so let's use chain of thought prompting to build this import/export feature as our last big feature to this project.\n\n```\nLet's build a complete export/import system step by step.\n\nStep 1: First, analyze what data we need to export:\n- All prompts with their metadata\n\nStep 2: Design the export JSON schema that includes:\n- Version number for future compatibility\n- Export timestamp\n- Statistics (total prompts, average rating, most used model)\n- Complete prompts array\n\nStep 3: Create the export function that:\n- Gathers all data from localStorage\n- Validates data integrity\n- Creates a blob and triggers download with timestamp\n\nStep 4: Create the import function that:\n- Reads the uploaded file\n- Validates the JSON structure and version\n- Checks for duplicate IDs\n- Merges or replaces existing data based on user choice\n\nStep 5: Add error recovery:\n- Backup existing data before import\n- Rollback on failure\n- Provide detailed error messages\n\nAdd the import and export buttons and merge conflict resolution prompts\n\nImplement this complete system with all steps. Think step by step.\n```\n","slug":"chain-of-thought","title":"Chain of Thought","section":"Advanced Prompting Techniques","icon":"info-circle","filePath":"/home/runner/work/practical-prompt-engineering/practical-prompt-engineering/lessons/03-advanced-prompting-techniques/B-chain-of-thought.md","nextSlug":"/practical-prompt-engineering/lessons/advanced-prompting-techniques/delimiters","prevSlug":"/practical-prompt-engineering/lessons/advanced-prompting-techniques/structured-output"}},"__N_SSG":true}