{"pageProps":{"post":{"attributes":{},"html":"<h1>Few Shot Prompting</h1>\n<p>Now we can assume that if zero-shot prompting was zero examples, and one-shot prompting was one example, then few shot prompting is going to mean two or more examples.</p>\n<p>And why would we want to do this?</p>\n<p><a href=\"https://arxiv.org/pdf/2005.14165\">Language Models are Few-Shot Learners</a> researched these prompts and proved that few-shot examples dramatically improved LLM performance. Also in the paper, there was evidence that while zero shot and one shot got more effective with model size, few shot seemed to increase more rapidly in accuracy as models got larger. Its definitely worth a read, or at least check out the graphs on how much better prompting can get with zero, one, and a few shots.</p>\n<p>So when should we use few-shot prompting?</p>\n<p>When we have complex patterns with multiple variations, classification tasks with multiple categories, when we want to standardize formats across a diverse array of inputs, when we have domain specific tasks that require context, and when consistency across varied outputs is really important.</p>\n<blockquote>\n<p>Note:</p>\n<ul>\n<li>diversity in examples matters</li>\n<li>include edge cases and failure cases</li>\n<li>keep examples concise but complete</li>\n<li>test in a few different chats with a few different number of examples to find what works best</li>\n</ul>\n</blockquote>\n<p>An example of few-shot prompting:</p>\n<pre><code><button class=\"copy-btn\">Copy</button>Analyze the business decision with the requested level of detail.\n\nDecision: Opening a new store location\nAnalysis Level: Quick take\nResponse: New location appears viable given foot traffic data and competitor absence, though initial investment is substantial.\n\nDecision: Switching software providers\nAnalysis Level: Standard review\nResponse: Migration offers long-term cost savings of 30% and better feature set. However, switching requires 2-month transition period with potential disruption to operations. Staff training needed but vendor provides support. Recommend phased rollout starting with non-critical systems.\n\nDecision: Launching a new product line\nAnalysis Level: Comprehensive assessment\nResponse: Market analysis indicates strong demand with 40% of surveyed customers expressing interest. Competitive landscape shows opportunity for differentiation through our unique manufacturing process. Financial projections suggest break-even within 18 months, with 25% profit margins by year 3. Risk factors include supply chain dependencies on single vendor and need for $2M initial investment. Manufacturing capacity exists but requires equipment upgrades. Marketing strategy should emphasize sustainability angle based on focus group feedback. Recommend soft launch in Q2 with limited geographic rollout, expanding nationally in Q4 based on performance metrics. Success criteria: 10,000 units sold in first quarter, customer satisfaction above 85%, and return rate below 5%.\n\nDecision: Implementing remote work policy\nAnalysis Level: Standard review\nResponse:\n</code></pre><p>For our prompt library, we want to add a &quot;notes&quot; feature that allows us to add notes to our prompts, in case we want to say &quot;worked better with this model&quot; or add the technique we used or something like that!</p>\n<blockquote>\n<p>Note: you will likely need to prompt the model again to build the feature after sending this prompt. This prompt uses an example to help the model &quot;architect&quot; this feature. Go through what it wants to build, prompt to make any adjustments you see fit, and then prompt the model to &quot;build this feature&quot; (or however you want to word it!)</p>\n</blockquote>\n<pre><code><button class=\"copy-btn\">Copy</button>I need you to create a prompt for implementing a new feature. Here are examples of effective feature implementation prompts:\n\n**EXAMPLE 1: Save/Delete Functionality Prompt**\nCreate a save and delete system for a prompt library application with the following requirements:\n\nTechnical Specifications:\n- Save button that persists prompts to localStorage\n- Delete button with confirmation dialog before removal\n- Visual feedback on successful save (green checkmark animation)\n- Trash icon with hover effect for delete action\n- Auto-save indicator when changes are detected\n\nProvide complete HTML, CSS, and JavaScript with:\n1. Semantic HTML with data attributes for prompt IDs\n2. CSS animations for save confirmation and delete hover states\n3. JavaScript with proper event delegation for dynamically added prompts\n4. localStorage integration with JSON serialization\n\nThe system should work with this data structure:\nconst prompts = [\n  { id: &#x27;prompt-001&#x27;, title: &quot;Blog Writer&quot;, content: &quot;Generate blog posts...&quot;, savedAt: Date.now() }\n];\n\nInclude error handling for localStorage quota exceeded and implement a &quot;Recently Deleted&quot; temporary storage (up to 5 items).\n\n**EXAMPLE 2: Star Rating Component Prompt**\nBuild a 5-star rating system for rating prompt effectiveness with these specifications:\n\nCore Requirements:\n- Interactive 5-star display (click to rate, hover to preview)\n- Half-star precision (4.5 stars possible)\n- Shows average rating and total number of ratings\n- Updates immediately without page refresh\n- Allows users to change their rating\n\nImplementation Details:\n- SVG stars for crisp display at any size\n- Gold fill for rated, gray outline for unrated\n- Smooth hover animations (scale and glow effect)\n- Display format: &quot;4.5 ★ (23 ratings)&quot;\n\nDeliver production-ready code including:\n1. HTML with accessible ARIA labels for screen readers\n2. CSS with star animations and responsive sizing\n3. JavaScript for rating logic and state management\n4. Comments explaining calculation methods\n\nData model to support:\n{\n  promptId: &#x27;prompt-001&#x27;,\n  ratings: [5, 4, 5, 3, 5], // Array of all ratings\n  userRating: 4, // Current user&#x27;s rating\n  averageRating: 4.4\n}\n\n**YOUR TASK:** Based on the examples above, create a detailed prompt for building a &quot;notes section&quot; feature where users can add, edit, save, and delete notes for each prompt in the library.\n\nThe prompt should follow the pattern shown in the examples:\n\n- Clear feature description\n- Specific technical requirements\n- Implementation details\n- Expected deliverables\n- Data structure/integration notes\n\nKeep it as simple as possible to create a working notes section with only the features mentioned in your task.\n</code></pre>","markdown":"# Few Shot Prompting\n\nNow we can assume that if zero-shot prompting was zero examples, and one-shot prompting was one example, then few shot prompting is going to mean two or more examples.\n\nAnd why would we want to do this?\n\n[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165) researched these prompts and proved that few-shot examples dramatically improved LLM performance. Also in the paper, there was evidence that while zero shot and one shot got more effective with model size, few shot seemed to increase more rapidly in accuracy as models got larger. Its definitely worth a read, or at least check out the graphs on how much better prompting can get with zero, one, and a few shots.\n\nSo when should we use few-shot prompting?\n\nWhen we have complex patterns with multiple variations, classification tasks with multiple categories, when we want to standardize formats across a diverse array of inputs, when we have domain specific tasks that require context, and when consistency across varied outputs is really important.\n\n> Note:\n> - diversity in examples matters\n> - include edge cases and failure cases\n> - keep examples concise but complete\n> - test in a few different chats with a few different number of examples to find what works best\n\nAn example of few-shot prompting:\n```\nAnalyze the business decision with the requested level of detail.\n\nDecision: Opening a new store location\nAnalysis Level: Quick take\nResponse: New location appears viable given foot traffic data and competitor absence, though initial investment is substantial.\n\nDecision: Switching software providers\nAnalysis Level: Standard review\nResponse: Migration offers long-term cost savings of 30% and better feature set. However, switching requires 2-month transition period with potential disruption to operations. Staff training needed but vendor provides support. Recommend phased rollout starting with non-critical systems.\n\nDecision: Launching a new product line\nAnalysis Level: Comprehensive assessment\nResponse: Market analysis indicates strong demand with 40% of surveyed customers expressing interest. Competitive landscape shows opportunity for differentiation through our unique manufacturing process. Financial projections suggest break-even within 18 months, with 25% profit margins by year 3. Risk factors include supply chain dependencies on single vendor and need for $2M initial investment. Manufacturing capacity exists but requires equipment upgrades. Marketing strategy should emphasize sustainability angle based on focus group feedback. Recommend soft launch in Q2 with limited geographic rollout, expanding nationally in Q4 based on performance metrics. Success criteria: 10,000 units sold in first quarter, customer satisfaction above 85%, and return rate below 5%.\n\nDecision: Implementing remote work policy\nAnalysis Level: Standard review\nResponse:\n```\n\nFor our prompt library, we want to add a \"notes\" feature that allows us to add notes to our prompts, in case we want to say \"worked better with this model\" or add the technique we used or something like that!\n\n > Note: you will likely need to prompt the model again to build the feature after sending this prompt. This prompt uses an example to help the model \"architect\" this feature. Go through what it wants to build, prompt to make any adjustments you see fit, and then prompt the model to \"build this feature\" (or however you want to word it!)\n\n```\nI need you to create a prompt for implementing a new feature. Here are examples of effective feature implementation prompts:\n\n**EXAMPLE 1: Save/Delete Functionality Prompt**\nCreate a save and delete system for a prompt library application with the following requirements:\n\nTechnical Specifications:\n- Save button that persists prompts to localStorage\n- Delete button with confirmation dialog before removal\n- Visual feedback on successful save (green checkmark animation)\n- Trash icon with hover effect for delete action\n- Auto-save indicator when changes are detected\n\nProvide complete HTML, CSS, and JavaScript with:\n1. Semantic HTML with data attributes for prompt IDs\n2. CSS animations for save confirmation and delete hover states\n3. JavaScript with proper event delegation for dynamically added prompts\n4. localStorage integration with JSON serialization\n\nThe system should work with this data structure:\nconst prompts = [\n  { id: 'prompt-001', title: \"Blog Writer\", content: \"Generate blog posts...\", savedAt: Date.now() }\n];\n\nInclude error handling for localStorage quota exceeded and implement a \"Recently Deleted\" temporary storage (up to 5 items).\n\n**EXAMPLE 2: Star Rating Component Prompt**\nBuild a 5-star rating system for rating prompt effectiveness with these specifications:\n\nCore Requirements:\n- Interactive 5-star display (click to rate, hover to preview)\n- Half-star precision (4.5 stars possible)\n- Shows average rating and total number of ratings\n- Updates immediately without page refresh\n- Allows users to change their rating\n\nImplementation Details:\n- SVG stars for crisp display at any size\n- Gold fill for rated, gray outline for unrated\n- Smooth hover animations (scale and glow effect)\n- Display format: \"4.5 ★ (23 ratings)\"\n\nDeliver production-ready code including:\n1. HTML with accessible ARIA labels for screen readers\n2. CSS with star animations and responsive sizing\n3. JavaScript for rating logic and state management\n4. Comments explaining calculation methods\n\nData model to support:\n{\n  promptId: 'prompt-001',\n  ratings: [5, 4, 5, 3, 5], // Array of all ratings\n  userRating: 4, // Current user's rating\n  averageRating: 4.4\n}\n\n**YOUR TASK:** Based on the examples above, create a detailed prompt for building a \"notes section\" feature where users can add, edit, save, and delete notes for each prompt in the library.\n\nThe prompt should follow the pattern shown in the examples:\n\n- Clear feature description\n- Specific technical requirements\n- Implementation details\n- Expected deliverables\n- Data structure/integration notes\n\nKeep it as simple as possible to create a working notes section with only the features mentioned in your task.\n```\n","slug":"few-shot","title":"Few Shot","section":"Core Prompting Techniques","icon":"info-circle","filePath":"/home/runner/work/practical-prompt-engineering/practical-prompt-engineering/lessons/02-core-prompting-techniques/D-few-shot.md","nextSlug":"/practical-prompt-engineering/lessons/core-prompting-techniques/context-placement","prevSlug":"/practical-prompt-engineering/lessons/core-prompting-techniques/one-shot"}},"__N_SSG":true}