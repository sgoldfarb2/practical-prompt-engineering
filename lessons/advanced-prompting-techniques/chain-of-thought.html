<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="apple-touch-icon" sizes="180x180" href="/practical-prompt-engineering/images/apple-touch-icon.png" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/practical-prompt-engineering/images/favicon-32x32.png" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/practical-prompt-engineering/images/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/practical-prompt-engineering/images/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/x-icon" href="/practical-prompt-engineering/images/favicon.ico" data-next-head=""/><title data-next-head="">Chain of Thought – Practical Prompt Engineering for Developers</title><meta name="description" content="Learn how to use Large Language Models (LLMs) like ChatGPT, Claude, and GitHub Copilot to build applications, generate code, and enhance your development workflow. This course covers prompt engineering techniques, best practices, and real-world examples to help you harness the power of AI in your projects." data-next-head=""/><meta name="keywords" content="Prompt,Engineering,Prompt Engineering,LLM,Large Language Model,AI,Artificial Intelligence,ChatGPT,Claude,Copilot,Cursor" data-next-head=""/><meta name="og:description" content="Learn how to use Large Language Models (LLMs) like ChatGPT, Claude, and GitHub Copilot to build applications, generate code, and enhance your development workflow. This course covers prompt engineering techniques, best practices, and real-world examples to help you harness the power of AI in your projects." data-next-head=""/><meta name="og:title" content="Chain of Thought – Practical Prompt Engineering for Developers" data-next-head=""/><meta name="og:image" content="/practical-prompt-engineering/images/social-share-cover.jpg" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><link data-next-font="size-adjust" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/practical-prompt-engineering/_next/static/css/494300e045a23fee.css" as="style"/><link rel="stylesheet" href="/practical-prompt-engineering/_next/static/css/494300e045a23fee.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/practical-prompt-engineering/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/practical-prompt-engineering/_next/static/chunks/webpack-cf792cf7e3f82e37.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/framework-b1e5f14688f9ffe6.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/main-bb2903324629cbc1.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/pages/_app-a82b77e4dbdbf3dd.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/pages/lessons/%5Bsection%5D/%5Bslug%5D-98978c15d4082bdc.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/Su_DcT-hcs7Ah5fxh9Obs/_buildManifest.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/Su_DcT-hcs7Ah5fxh9Obs/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="remix-app"><header class="navbar"><h1 class="navbar-brand"><a href="/practical-prompt-engineering">Practical Prompt Engineering for Developers</a></h1><div class="navbar-info"><a href="https://frontendmasters.com/courses/" class="cta-btn">Watch on Frontend Masters</a></div></header><div class="content-container"><div class="main"><div class="lesson-container"><div class="lesson"><div class="lesson-content"><h1>Chain of Thought (CoT)</h1>
<p>There was a study <a href="https://arxiv.org/pdf/2205.11916">Large Language Models are Zero-Shot Reasoners</a> and it looked at the accuracy of LLMs with different prompts.</p>
<p>There has been research on the phrase &quot;let&#39;s think step by step&quot; added to prompts and this study looked specifically at this &quot;zero-shot chain of thought prompt&quot; performance on a diverse set of reasoning tasks including arithmetic and logical reasoning tasks without any few shot examples.</p>
<p>Amazingly, accuracy on the multi-arithmetic problems went from 17.7% to 78.7%.</p>
<p>Something else amazing about this &quot;chain of thought&quot; reasoning is that the reasoning performance of the models got better as the models got larger as well.</p>
<p>Its important to really appreciate just this simple five word addition to our prompts because let&#39;s think step by step is versatile and task-agnostic, you can use it for basically anything...code generation, math problems, complex reasoning, etc.</p>
<p>I&#39;d highly encourage reading the paper to understand more of why this works.</p>
<p>Here is an example of using CoT reasoning in a prompt:</p>
<pre><code><button class="copy-btn">Copy</button>Can penguins fly?
Think through this step by step.
</code></pre><p>For our prompt library, let&#39;s build something complex, like the ability to import and export our prompts. Since we are only saving them currently to localStorage, they are going to disappear on us, so if we build an export system to JSON, then we can download the JSON and we can import it the next time we load our prompt library, and we can just have it all back without worrying about where those files need to live or adding a database or anything like that, so let&#39;s use chain of thought prompting to build this import/export feature as our last big feature to this project.</p>
<pre><code><button class="copy-btn">Copy</button>Let&#x27;s build a complete export/import system step by step.

Step 1: First, analyze what data we need to export:
- All prompts with their metadata

Step 2: Design the export JSON schema that includes:
- Version number for future compatibility
- Export timestamp
- Statistics (total prompts, average rating, most used model)
- Complete prompts array

Step 3: Create the export function that:
- Gathers all data from localStorage
- Validates data integrity
- Creates a blob and triggers download with timestamp

Step 4: Create the import function that:
- Reads the uploaded file
- Validates the JSON structure and version
- Checks for duplicate IDs
- Merges or replaces existing data based on user choice

Step 5: Add error recovery:
- Backup existing data before import
- Rollback on failure
- Provide detailed error messages

Add the import and export buttons and merge conflict resolution prompts

Implement this complete system with all steps. Think step by step.
</code></pre></div><div class="lesson-links"><a href="/practical-prompt-engineering/lessons/advanced-prompting-techniques/structured-output" class="prev">← Previous</a><a href="/practical-prompt-engineering/lessons/advanced-prompting-techniques/delimiters" class="next">Next →</a></div></div><div class="details-bg"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="154" height="154" viewBox="0 0 154 154"><defs><clipPath id="clip-path"><rect id="Rectangle_2238" data-name="Rectangle 2238" width="154" height="154" transform="translate(9467 350)" fill="#fff" stroke="#707070" stroke-width="1"></rect></clipPath><clipPath id="clip-corner-image-active"><rect width="154" height="154"></rect></clipPath></defs><g id="corner-image-active" clip-path="url(#clip-corner-image-active)"><g id="Corner-image-active-2" data-name="Corner-image-active" transform="translate(-9467 -350)" clip-path="url(#clip-path)"><path id="Subtraction_34" data-name="Subtraction 34" d="M-3857.365,1740.766h0l-7.07-7.07,12.89-12.89v14.142l-5.818,5.818Zm-14.142-14.142h0l-7.071-7.07,27.033-27.033v14.143l-19.96,19.96Zm-14.143-14.143h0l-7.07-7.069,41.175-41.175v14.142Zm-14.142-14.142h0l-7.07-7.069,55.317-55.317v14.142Zm-14.142-14.142h0l-7.07-7.069,69.459-69.459v14.142Zm-14.142-14.142h0l-7.07-7.069,76.739-76.739h6.862v7.28Zm-14.143-14.143h0l-7.07-7.069,62.6-62.6h14.142Zm-14.142-14.142h0l-7.07-7.069,48.454-48.454h14.142Zm-14.142-14.142h0l-7.07-7.069,34.312-34.312h14.142Zm-14.142-14.142h0l-7.07-7.069,20.17-20.17h14.142Zm-14.142-14.142h0l-7.071-7.071,6.027-6.027h14.144l-13.1,13.1Zm367.24-56.114v-.909l.455.455-.453.453Z" transform="translate(13472.546 -1236.766)" fill="var(--corner-fill)"></path></g></g></svg></div></div></div></div><footer class="footer"><ul class="socials"><li class="social"><a href="https://github.com/sgoldfarb2"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="32" height="32" viewBox="0 0 32 32"><defs><clipPath id="clip-github-social"><rect width="32" height="32"></rect></clipPath></defs><g id="github-social" clip-path="url(#clip-github-social)"><g id="Group_272" data-name="Group 272" transform="translate(13522.5 -6994)"><path id="Subtraction_33" data-name="Subtraction 33" d="M-24967.5,8041a15.9,15.9,0,0,1-11.312-4.688A15.893,15.893,0,0,1-24983.5,8025a15.893,15.893,0,0,1,4.689-11.315A15.894,15.894,0,0,1-24967.5,8009a15.894,15.894,0,0,1,11.313,4.686A15.893,15.893,0,0,1-24951.5,8025a15.893,15.893,0,0,1-4.689,11.313A15.9,15.9,0,0,1-24967.5,8041Zm-3.781-4.571h0v3.918h7.895v-6.665a1.836,1.836,0,0,0-1.2-1.718c5.1-.617,7.467-2.975,7.467-7.424a7.176,7.176,0,0,0-1.637-4.728,6.74,6.74,0,0,0,.275-1.812,4.34,4.34,0,0,0-.52-2.452.574.574,0,0,0-.359-.1c-1.061,0-3.465,1.411-3.936,1.694a16.644,16.644,0,0,0-4.2-.489,16.379,16.379,0,0,0-3.969.445c-.846-.5-2.91-1.649-3.859-1.649a.566.566,0,0,0-.354.095,4.3,4.3,0,0,0-.521,2.452,6.7,6.7,0,0,0,.244,1.718,7.346,7.346,0,0,0-1.6,4.822,7.263,7.263,0,0,0,1.533,4.985c1.193,1.359,3.115,2.165,5.871,2.464a1.826,1.826,0,0,0-1.129,1.693v.5h0l-.006,0a7.121,7.121,0,0,1-2.033.363,2.608,2.608,0,0,1-.965-.158,4.438,4.438,0,0,1-1.836-1.881,2.361,2.361,0,0,0-1.248-1.091,3.472,3.472,0,0,0-1.217-.3.584.584,0,0,0-.545.224.282.282,0,0,0,.027.367,1.875,1.875,0,0,0,.447.307,4.732,4.732,0,0,1,.561.355,10.726,10.726,0,0,1,1.682,2.755c.043.092.078.163.105.217a3.876,3.876,0,0,0,2.42,1.185,6.036,6.036,0,0,0,.607.025c.875,0,1.988-.124,2-.125Z" transform="translate(11461 -1015)" fill="var(--footer-icons)"></path><g id="Ellipse_670" data-name="Ellipse 670" transform="translate(-13522.5 6994)" fill="none" stroke="var(--footer-icons)" stroke-width="1"><circle cx="16" cy="16" r="16" stroke="none"></circle><circle cx="16" cy="16" r="15.5" fill="none"></circle></g></g></g></svg></a></li><li class="social"><a href="https://linkedin.com/in/sabrinagoldfarb"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="32" height="32" viewBox="0 0 32 32"><defs><clipPath id="clip-linkedin-social"><rect width="32" height="32"></rect></clipPath></defs><g id="linkedin-social" clip-path="url(#clip-linkedin-social)"><g id="Group_270" data-name="Group 270" transform="translate(-86.349 -633.073)"><path id="Path_375" data-name="Path 375" d="M115.789,633.073a2.324,2.324,0,0,1,1.682.676,2.194,2.194,0,0,1,.695,1.627V662.8a2.131,2.131,0,0,1-.695,1.609,2.314,2.314,0,0,1-1.646.659H88.69a2.307,2.307,0,0,1-1.646-.659,2.128,2.128,0,0,1-.695-1.609V635.376a2.19,2.19,0,0,1,.695-1.627,2.322,2.322,0,0,1,1.682-.676h27.063Zm-20.224,9.672a2.561,2.561,0,0,0,0-3.584,2.658,2.658,0,0,0-1.938-.712,2.724,2.724,0,0,0-1.957.712,2.371,2.371,0,0,0-.75,1.792,2.4,2.4,0,0,0,.731,1.792,2.605,2.605,0,0,0,1.9.713h.037A2.7,2.7,0,0,0,95.565,642.745ZM96,645.434H91.213V659.88H96Zm17.3,6.144a7.007,7.007,0,0,0-1.573-4.9,5.68,5.68,0,0,0-6.839-.769,5.663,5.663,0,0,0-1.426,1.573v-2.048H98.674q.036.841,0,7.717v6.728h4.791V651.8a3.592,3.592,0,0,1,.146-1.17,2.913,2.913,0,0,1,.878-1.206,2.429,2.429,0,0,1,1.609-.549,2.108,2.108,0,0,1,1.865.914,4.265,4.265,0,0,1,.549,2.341v7.752H113.3Z" fill="var(--footer-icons)"></path></g></g></svg></a></li><li class="social"><div class="terms"><p>Content Licensed Under CC-BY-NC-4.0</p><p>Code Samples and Exercises Licensed Under Apache 2.0</p><p>Site Designed by<!-- --> <a href="https://www.alexdanielson.com/">Alex Danielson</a></p></div></li></ul><div class="theme-icons"><button aria-label="Activate dark mode" title="Activate dark mode" class="theme-toggle"><svg xmlns="http://www.w3.org/2000/svg" width="36px" height="100%" viewBox="0 -960 960 960" fill="var(--text-footer)" role="img"><title>Dark Mode Icon</title><path d="M480-120q-150 0-255-105T120-480q0-150 105-255t255-105q14 0 27.5 1t26.5 3q-41 29-65.5 75.5T444-660q0 90 63 153t153 63q55 0 101-24.5t75-65.5q2 13 3 26.5t1 27.5q0 150-105 255T480-120Zm0-80q88 0 158-48.5T740-375q-20 5-40 8t-40 3q-123 0-209.5-86.5T364-660q0-20 3-40t8-40q-78 32-126.5 102T200-480q0 116 82 198t198 82Z"></path></svg></button></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"attributes":{},"html":"\u003ch1\u003eChain of Thought (CoT)\u003c/h1\u003e\n\u003cp\u003eThere was a study \u003ca href=\"https://arxiv.org/pdf/2205.11916\"\u003eLarge Language Models are Zero-Shot Reasoners\u003c/a\u003e and it looked at the accuracy of LLMs with different prompts.\u003c/p\u003e\n\u003cp\u003eThere has been research on the phrase \u0026quot;let\u0026#39;s think step by step\u0026quot; added to prompts and this study looked specifically at this \u0026quot;zero-shot chain of thought prompt\u0026quot; performance on a diverse set of reasoning tasks including arithmetic and logical reasoning tasks without any few shot examples.\u003c/p\u003e\n\u003cp\u003eAmazingly, accuracy on the multi-arithmetic problems went from 17.7% to 78.7%.\u003c/p\u003e\n\u003cp\u003eSomething else amazing about this \u0026quot;chain of thought\u0026quot; reasoning is that the reasoning performance of the models got better as the models got larger as well.\u003c/p\u003e\n\u003cp\u003eIts important to really appreciate just this simple five word addition to our prompts because let\u0026#39;s think step by step is versatile and task-agnostic, you can use it for basically anything...code generation, math problems, complex reasoning, etc.\u003c/p\u003e\n\u003cp\u003eI\u0026#39;d highly encourage reading the paper to understand more of why this works.\u003c/p\u003e\n\u003cp\u003eHere is an example of using CoT reasoning in a prompt:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cbutton class=\"copy-btn\"\u003eCopy\u003c/button\u003eCan penguins fly?\nThink through this step by step.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFor our prompt library, let\u0026#39;s build something complex, like the ability to import and export our prompts. Since we are only saving them currently to localStorage, they are going to disappear on us, so if we build an export system to JSON, then we can download the JSON and we can import it the next time we load our prompt library, and we can just have it all back without worrying about where those files need to live or adding a database or anything like that, so let\u0026#39;s use chain of thought prompting to build this import/export feature as our last big feature to this project.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cbutton class=\"copy-btn\"\u003eCopy\u003c/button\u003eLet\u0026#x27;s build a complete export/import system step by step.\n\nStep 1: First, analyze what data we need to export:\n- All prompts with their metadata\n\nStep 2: Design the export JSON schema that includes:\n- Version number for future compatibility\n- Export timestamp\n- Statistics (total prompts, average rating, most used model)\n- Complete prompts array\n\nStep 3: Create the export function that:\n- Gathers all data from localStorage\n- Validates data integrity\n- Creates a blob and triggers download with timestamp\n\nStep 4: Create the import function that:\n- Reads the uploaded file\n- Validates the JSON structure and version\n- Checks for duplicate IDs\n- Merges or replaces existing data based on user choice\n\nStep 5: Add error recovery:\n- Backup existing data before import\n- Rollback on failure\n- Provide detailed error messages\n\nAdd the import and export buttons and merge conflict resolution prompts\n\nImplement this complete system with all steps. Think step by step.\n\u003c/code\u003e\u003c/pre\u003e","markdown":"# Chain of Thought (CoT)\n\nThere was a study [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916) and it looked at the accuracy of LLMs with different prompts.\n\nThere has been research on the phrase \"let's think step by step\" added to prompts and this study looked specifically at this \"zero-shot chain of thought prompt\" performance on a diverse set of reasoning tasks including arithmetic and logical reasoning tasks without any few shot examples.\n\nAmazingly, accuracy on the multi-arithmetic problems went from 17.7% to 78.7%.\n\nSomething else amazing about this \"chain of thought\" reasoning is that the reasoning performance of the models got better as the models got larger as well.\n\nIts important to really appreciate just this simple five word addition to our prompts because let's think step by step is versatile and task-agnostic, you can use it for basically anything...code generation, math problems, complex reasoning, etc.\n\nI'd highly encourage reading the paper to understand more of why this works.\n\nHere is an example of using CoT reasoning in a prompt:\n```\nCan penguins fly?\nThink through this step by step.\n```\n\nFor our prompt library, let's build something complex, like the ability to import and export our prompts. Since we are only saving them currently to localStorage, they are going to disappear on us, so if we build an export system to JSON, then we can download the JSON and we can import it the next time we load our prompt library, and we can just have it all back without worrying about where those files need to live or adding a database or anything like that, so let's use chain of thought prompting to build this import/export feature as our last big feature to this project.\n\n```\nLet's build a complete export/import system step by step.\n\nStep 1: First, analyze what data we need to export:\n- All prompts with their metadata\n\nStep 2: Design the export JSON schema that includes:\n- Version number for future compatibility\n- Export timestamp\n- Statistics (total prompts, average rating, most used model)\n- Complete prompts array\n\nStep 3: Create the export function that:\n- Gathers all data from localStorage\n- Validates data integrity\n- Creates a blob and triggers download with timestamp\n\nStep 4: Create the import function that:\n- Reads the uploaded file\n- Validates the JSON structure and version\n- Checks for duplicate IDs\n- Merges or replaces existing data based on user choice\n\nStep 5: Add error recovery:\n- Backup existing data before import\n- Rollback on failure\n- Provide detailed error messages\n\nAdd the import and export buttons and merge conflict resolution prompts\n\nImplement this complete system with all steps. Think step by step.\n```\n","slug":"chain-of-thought","title":"Chain of Thought","section":"Advanced Prompting Techniques","icon":"info-circle","filePath":"/home/runner/work/practical-prompt-engineering/practical-prompt-engineering/lessons/03-advanced-prompting-techniques/B-chain-of-thought.md","nextSlug":"/practical-prompt-engineering/lessons/advanced-prompting-techniques/delimiters","prevSlug":"/practical-prompt-engineering/lessons/advanced-prompting-techniques/structured-output"}},"__N_SSG":true},"page":"/lessons/[section]/[slug]","query":{"section":"advanced-prompting-techniques","slug":"chain-of-thought"},"buildId":"Su_DcT-hcs7Ah5fxh9Obs","assetPrefix":"/practical-prompt-engineering","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>