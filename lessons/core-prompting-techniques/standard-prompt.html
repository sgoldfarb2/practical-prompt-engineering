<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="apple-touch-icon" sizes="180x180" href="/practical-prompt-engineering/images/apple-touch-icon.png" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/practical-prompt-engineering/images/favicon-32x32.png" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/practical-prompt-engineering/images/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/practical-prompt-engineering/images/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/x-icon" href="/practical-prompt-engineering/images/favicon.ico" data-next-head=""/><title data-next-head="">Standard Prompt – Practical Prompt Engineering for Developers</title><meta name="description" content="Learn how to use Large Language Models (LLMs) like ChatGPT, Claude, and GitHub Copilot to build applications, generate code, and enhance your development workflow. This course covers prompt engineering techniques, best practices, and real-world examples to help you harness the power of AI in your projects." data-next-head=""/><meta name="keywords" content="Prompt,Engineering,Prompt Engineering,LLM,Large Language Model,AI,Artificial Intelligence,ChatGPT,Claude,Copilot,Cursor" data-next-head=""/><meta name="og:description" content="Learn how to use Large Language Models (LLMs) like ChatGPT, Claude, and GitHub Copilot to build applications, generate code, and enhance your development workflow. This course covers prompt engineering techniques, best practices, and real-world examples to help you harness the power of AI in your projects." data-next-head=""/><meta name="og:title" content="Standard Prompt – Practical Prompt Engineering for Developers" data-next-head=""/><meta name="og:image" content="/practical-prompt-engineering/images/social-share-cover.jpg" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><link data-next-font="size-adjust" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/practical-prompt-engineering/_next/static/css/494300e045a23fee.css" as="style"/><link rel="stylesheet" href="/practical-prompt-engineering/_next/static/css/494300e045a23fee.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/practical-prompt-engineering/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/practical-prompt-engineering/_next/static/chunks/webpack-cf792cf7e3f82e37.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/framework-b1e5f14688f9ffe6.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/main-bb2903324629cbc1.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/pages/_app-a82b77e4dbdbf3dd.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/chunks/pages/lessons/%5Bsection%5D/%5Bslug%5D-98978c15d4082bdc.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/Su_DcT-hcs7Ah5fxh9Obs/_buildManifest.js" defer=""></script><script src="/practical-prompt-engineering/_next/static/Su_DcT-hcs7Ah5fxh9Obs/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="remix-app"><header class="navbar"><h1 class="navbar-brand"><a href="/practical-prompt-engineering">Practical Prompt Engineering for Developers</a></h1><div class="navbar-info"><a href="https://frontendmasters.com/courses/" class="cta-btn">Watch on Frontend Masters</a></div></header><div class="content-container"><div class="main"><div class="lesson-container"><div class="lesson"><div class="lesson-content"><h1>Standard Prompts</h1>
<p>The first prompting technique is something you&#39;re <em>already</em> doing every time you use LLMs whether you know it or not!</p>
<p>Standard prompts are just asking direct questions or giving direct instructions to your AI assistant. This is just the official term that&#39;s used in academic papers and research.</p>
<p>The standard prompt isn&#39;t using any special formatting or techniques, just regular questions like &quot;Write me a JavaScript function to sort an array and remove duplicates&quot;, or &quot;Explain to me why thunder is so scary&quot;, or &quot;When did the video game Apex Legends release?&quot; Straightforward questions and commands. Nothing fancy! Try these for yourself in your favorite AI companion (I am personally a huge fan of using Claude in the browser for these!)</p>
<p>But this is the basis and the first building block of every subsequent kind of prompt. And here&#39;s something important to consider - this works exactly like asking a friend a question. If you ask a vague question, you get a vague answer. If you ask a precise question, you get a precise answer. The model works with what you give it, same as any human you walk up to today and ask a question to. </p>
<p>Think about if you were to ask a coworker for help on your codebase. If you were to say to them &quot;this doesn&#39;t work&quot;, they might guess at why and could be write but could be off because they have no <em>context</em> to what&#39;s wrong. But if you&#39;re like &quot;hey, on line 56 when I passed in an empty array to this function, I got an error that says...&quot; they can help you a lot better.</p>
<p>As part of this course, we are building an HTML/CSS/JS local prompt library where we can write a prompt, send it to the AI of our choosing, and use the output code to simply &quot;vibe code&quot; this project.</p>
<p>So now a note on this. As this is going to involve a lot of lines of code and prompts that adjust lines of code as we go, I suggest experimenting with Cursor, Copilot, or Claude Code for these prompts. You are welcome to use ChatGPT or Claude in the browser, but you&#39;ll have to copy/paste your code every time, which isn&#39;t convenient, more prone to errors and rate limits, and can take a lot of time.</p>
<p>So to see an example of a standard prompt in writing code, let&#39;s ask our AI assistant to write some code for us:</p>
<pre><code><button class="copy-btn">Copy</button>Create a prompt library application that lets users save and delete prompts.

Users should be able to:
- Enter a title and content for their prompt
- Save it to localStorage
- See all their saved prompts displayed on the page
- Delete prompts they no longer need

Make it look clean and professional with HTML, CSS, and JavaScript.
</code></pre><p>Your output will be different than mine (remember models are non-deterministic!) but depending on the model and provider, it may be very different than what I generated.</p>
<p>One thing you may notice when doing this is often your assistant will add additional features it wants to. It makes a lot of <em>assumptions</em> which introduces a lot more <em>randomness</em> than we want if we are going to use these models to generate code for us.</p>
<p>So, as an FYI, I deleted this scaffold for the project and will regenerate it in the next section.</p>
<p>But we can see these standard prompts already are pretty powerful! Now, let&#39;s add some technique to our prompts.</p>
</div><div class="lesson-links"><a href="/practical-prompt-engineering/lessons/introduction/temperature-top-p-tokens-and-context" class="prev">← Previous</a><a href="/practical-prompt-engineering/lessons/core-prompting-techniques/zero-shot" class="next">Next →</a></div></div><div class="details-bg"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="154" height="154" viewBox="0 0 154 154"><defs><clipPath id="clip-path"><rect id="Rectangle_2238" data-name="Rectangle 2238" width="154" height="154" transform="translate(9467 350)" fill="#fff" stroke="#707070" stroke-width="1"></rect></clipPath><clipPath id="clip-corner-image-active"><rect width="154" height="154"></rect></clipPath></defs><g id="corner-image-active" clip-path="url(#clip-corner-image-active)"><g id="Corner-image-active-2" data-name="Corner-image-active" transform="translate(-9467 -350)" clip-path="url(#clip-path)"><path id="Subtraction_34" data-name="Subtraction 34" d="M-3857.365,1740.766h0l-7.07-7.07,12.89-12.89v14.142l-5.818,5.818Zm-14.142-14.142h0l-7.071-7.07,27.033-27.033v14.143l-19.96,19.96Zm-14.143-14.143h0l-7.07-7.069,41.175-41.175v14.142Zm-14.142-14.142h0l-7.07-7.069,55.317-55.317v14.142Zm-14.142-14.142h0l-7.07-7.069,69.459-69.459v14.142Zm-14.142-14.142h0l-7.07-7.069,76.739-76.739h6.862v7.28Zm-14.143-14.143h0l-7.07-7.069,62.6-62.6h14.142Zm-14.142-14.142h0l-7.07-7.069,48.454-48.454h14.142Zm-14.142-14.142h0l-7.07-7.069,34.312-34.312h14.142Zm-14.142-14.142h0l-7.07-7.069,20.17-20.17h14.142Zm-14.142-14.142h0l-7.071-7.071,6.027-6.027h14.144l-13.1,13.1Zm367.24-56.114v-.909l.455.455-.453.453Z" transform="translate(13472.546 -1236.766)" fill="var(--corner-fill)"></path></g></g></svg></div></div></div></div><footer class="footer"><ul class="socials"><li class="social"><a href="https://github.com/sgoldfarb2"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="32" height="32" viewBox="0 0 32 32"><defs><clipPath id="clip-github-social"><rect width="32" height="32"></rect></clipPath></defs><g id="github-social" clip-path="url(#clip-github-social)"><g id="Group_272" data-name="Group 272" transform="translate(13522.5 -6994)"><path id="Subtraction_33" data-name="Subtraction 33" d="M-24967.5,8041a15.9,15.9,0,0,1-11.312-4.688A15.893,15.893,0,0,1-24983.5,8025a15.893,15.893,0,0,1,4.689-11.315A15.894,15.894,0,0,1-24967.5,8009a15.894,15.894,0,0,1,11.313,4.686A15.893,15.893,0,0,1-24951.5,8025a15.893,15.893,0,0,1-4.689,11.313A15.9,15.9,0,0,1-24967.5,8041Zm-3.781-4.571h0v3.918h7.895v-6.665a1.836,1.836,0,0,0-1.2-1.718c5.1-.617,7.467-2.975,7.467-7.424a7.176,7.176,0,0,0-1.637-4.728,6.74,6.74,0,0,0,.275-1.812,4.34,4.34,0,0,0-.52-2.452.574.574,0,0,0-.359-.1c-1.061,0-3.465,1.411-3.936,1.694a16.644,16.644,0,0,0-4.2-.489,16.379,16.379,0,0,0-3.969.445c-.846-.5-2.91-1.649-3.859-1.649a.566.566,0,0,0-.354.095,4.3,4.3,0,0,0-.521,2.452,6.7,6.7,0,0,0,.244,1.718,7.346,7.346,0,0,0-1.6,4.822,7.263,7.263,0,0,0,1.533,4.985c1.193,1.359,3.115,2.165,5.871,2.464a1.826,1.826,0,0,0-1.129,1.693v.5h0l-.006,0a7.121,7.121,0,0,1-2.033.363,2.608,2.608,0,0,1-.965-.158,4.438,4.438,0,0,1-1.836-1.881,2.361,2.361,0,0,0-1.248-1.091,3.472,3.472,0,0,0-1.217-.3.584.584,0,0,0-.545.224.282.282,0,0,0,.027.367,1.875,1.875,0,0,0,.447.307,4.732,4.732,0,0,1,.561.355,10.726,10.726,0,0,1,1.682,2.755c.043.092.078.163.105.217a3.876,3.876,0,0,0,2.42,1.185,6.036,6.036,0,0,0,.607.025c.875,0,1.988-.124,2-.125Z" transform="translate(11461 -1015)" fill="var(--footer-icons)"></path><g id="Ellipse_670" data-name="Ellipse 670" transform="translate(-13522.5 6994)" fill="none" stroke="var(--footer-icons)" stroke-width="1"><circle cx="16" cy="16" r="16" stroke="none"></circle><circle cx="16" cy="16" r="15.5" fill="none"></circle></g></g></g></svg></a></li><li class="social"><a href="https://linkedin.com/in/sabrinagoldfarb"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="32" height="32" viewBox="0 0 32 32"><defs><clipPath id="clip-linkedin-social"><rect width="32" height="32"></rect></clipPath></defs><g id="linkedin-social" clip-path="url(#clip-linkedin-social)"><g id="Group_270" data-name="Group 270" transform="translate(-86.349 -633.073)"><path id="Path_375" data-name="Path 375" d="M115.789,633.073a2.324,2.324,0,0,1,1.682.676,2.194,2.194,0,0,1,.695,1.627V662.8a2.131,2.131,0,0,1-.695,1.609,2.314,2.314,0,0,1-1.646.659H88.69a2.307,2.307,0,0,1-1.646-.659,2.128,2.128,0,0,1-.695-1.609V635.376a2.19,2.19,0,0,1,.695-1.627,2.322,2.322,0,0,1,1.682-.676h27.063Zm-20.224,9.672a2.561,2.561,0,0,0,0-3.584,2.658,2.658,0,0,0-1.938-.712,2.724,2.724,0,0,0-1.957.712,2.371,2.371,0,0,0-.75,1.792,2.4,2.4,0,0,0,.731,1.792,2.605,2.605,0,0,0,1.9.713h.037A2.7,2.7,0,0,0,95.565,642.745ZM96,645.434H91.213V659.88H96Zm17.3,6.144a7.007,7.007,0,0,0-1.573-4.9,5.68,5.68,0,0,0-6.839-.769,5.663,5.663,0,0,0-1.426,1.573v-2.048H98.674q.036.841,0,7.717v6.728h4.791V651.8a3.592,3.592,0,0,1,.146-1.17,2.913,2.913,0,0,1,.878-1.206,2.429,2.429,0,0,1,1.609-.549,2.108,2.108,0,0,1,1.865.914,4.265,4.265,0,0,1,.549,2.341v7.752H113.3Z" fill="var(--footer-icons)"></path></g></g></svg></a></li><li class="social"><div class="terms"><p>Content Licensed Under CC-BY-NC-4.0</p><p>Code Samples and Exercises Licensed Under Apache 2.0</p><p>Site Designed by<!-- --> <a href="https://www.alexdanielson.com/">Alex Danielson</a></p></div></li></ul><div class="theme-icons"><button aria-label="Activate dark mode" title="Activate dark mode" class="theme-toggle"><svg xmlns="http://www.w3.org/2000/svg" width="36px" height="100%" viewBox="0 -960 960 960" fill="var(--text-footer)" role="img"><title>Dark Mode Icon</title><path d="M480-120q-150 0-255-105T120-480q0-150 105-255t255-105q14 0 27.5 1t26.5 3q-41 29-65.5 75.5T444-660q0 90 63 153t153 63q55 0 101-24.5t75-65.5q2 13 3 26.5t1 27.5q0 150-105 255T480-120Zm0-80q88 0 158-48.5T740-375q-20 5-40 8t-40 3q-123 0-209.5-86.5T364-660q0-20 3-40t8-40q-78 32-126.5 102T200-480q0 116 82 198t198 82Z"></path></svg></button></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"attributes":{},"html":"\u003ch1\u003eStandard Prompts\u003c/h1\u003e\n\u003cp\u003eThe first prompting technique is something you\u0026#39;re \u003cem\u003ealready\u003c/em\u003e doing every time you use LLMs whether you know it or not!\u003c/p\u003e\n\u003cp\u003eStandard prompts are just asking direct questions or giving direct instructions to your AI assistant. This is just the official term that\u0026#39;s used in academic papers and research.\u003c/p\u003e\n\u003cp\u003eThe standard prompt isn\u0026#39;t using any special formatting or techniques, just regular questions like \u0026quot;Write me a JavaScript function to sort an array and remove duplicates\u0026quot;, or \u0026quot;Explain to me why thunder is so scary\u0026quot;, or \u0026quot;When did the video game Apex Legends release?\u0026quot; Straightforward questions and commands. Nothing fancy! Try these for yourself in your favorite AI companion (I am personally a huge fan of using Claude in the browser for these!)\u003c/p\u003e\n\u003cp\u003eBut this is the basis and the first building block of every subsequent kind of prompt. And here\u0026#39;s something important to consider - this works exactly like asking a friend a question. If you ask a vague question, you get a vague answer. If you ask a precise question, you get a precise answer. The model works with what you give it, same as any human you walk up to today and ask a question to. \u003c/p\u003e\n\u003cp\u003eThink about if you were to ask a coworker for help on your codebase. If you were to say to them \u0026quot;this doesn\u0026#39;t work\u0026quot;, they might guess at why and could be write but could be off because they have no \u003cem\u003econtext\u003c/em\u003e to what\u0026#39;s wrong. But if you\u0026#39;re like \u0026quot;hey, on line 56 when I passed in an empty array to this function, I got an error that says...\u0026quot; they can help you a lot better.\u003c/p\u003e\n\u003cp\u003eAs part of this course, we are building an HTML/CSS/JS local prompt library where we can write a prompt, send it to the AI of our choosing, and use the output code to simply \u0026quot;vibe code\u0026quot; this project.\u003c/p\u003e\n\u003cp\u003eSo now a note on this. As this is going to involve a lot of lines of code and prompts that adjust lines of code as we go, I suggest experimenting with Cursor, Copilot, or Claude Code for these prompts. You are welcome to use ChatGPT or Claude in the browser, but you\u0026#39;ll have to copy/paste your code every time, which isn\u0026#39;t convenient, more prone to errors and rate limits, and can take a lot of time.\u003c/p\u003e\n\u003cp\u003eSo to see an example of a standard prompt in writing code, let\u0026#39;s ask our AI assistant to write some code for us:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cbutton class=\"copy-btn\"\u003eCopy\u003c/button\u003eCreate a prompt library application that lets users save and delete prompts.\n\nUsers should be able to:\n- Enter a title and content for their prompt\n- Save it to localStorage\n- See all their saved prompts displayed on the page\n- Delete prompts they no longer need\n\nMake it look clean and professional with HTML, CSS, and JavaScript.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYour output will be different than mine (remember models are non-deterministic!) but depending on the model and provider, it may be very different than what I generated.\u003c/p\u003e\n\u003cp\u003eOne thing you may notice when doing this is often your assistant will add additional features it wants to. It makes a lot of \u003cem\u003eassumptions\u003c/em\u003e which introduces a lot more \u003cem\u003erandomness\u003c/em\u003e than we want if we are going to use these models to generate code for us.\u003c/p\u003e\n\u003cp\u003eSo, as an FYI, I deleted this scaffold for the project and will regenerate it in the next section.\u003c/p\u003e\n\u003cp\u003eBut we can see these standard prompts already are pretty powerful! Now, let\u0026#39;s add some technique to our prompts.\u003c/p\u003e\n","markdown":"# Standard Prompts\n\nThe first prompting technique is something you're *already* doing every time you use LLMs whether you know it or not!\n\nStandard prompts are just asking direct questions or giving direct instructions to your AI assistant. This is just the official term that's used in academic papers and research.\n\nThe standard prompt isn't using any special formatting or techniques, just regular questions like \"Write me a JavaScript function to sort an array and remove duplicates\", or \"Explain to me why thunder is so scary\", or \"When did the video game Apex Legends release?\" Straightforward questions and commands. Nothing fancy! Try these for yourself in your favorite AI companion (I am personally a huge fan of using Claude in the browser for these!)\n\nBut this is the basis and the first building block of every subsequent kind of prompt. And here's something important to consider - this works exactly like asking a friend a question. If you ask a vague question, you get a vague answer. If you ask a precise question, you get a precise answer. The model works with what you give it, same as any human you walk up to today and ask a question to. \n\nThink about if you were to ask a coworker for help on your codebase. If you were to say to them \"this doesn't work\", they might guess at why and could be write but could be off because they have no *context* to what's wrong. But if you're like \"hey, on line 56 when I passed in an empty array to this function, I got an error that says...\" they can help you a lot better.\n\nAs part of this course, we are building an HTML/CSS/JS local prompt library where we can write a prompt, send it to the AI of our choosing, and use the output code to simply \"vibe code\" this project.\n\nSo now a note on this. As this is going to involve a lot of lines of code and prompts that adjust lines of code as we go, I suggest experimenting with Cursor, Copilot, or Claude Code for these prompts. You are welcome to use ChatGPT or Claude in the browser, but you'll have to copy/paste your code every time, which isn't convenient, more prone to errors and rate limits, and can take a lot of time.\n\nSo to see an example of a standard prompt in writing code, let's ask our AI assistant to write some code for us:\n\n```\nCreate a prompt library application that lets users save and delete prompts.\n\nUsers should be able to:\n- Enter a title and content for their prompt\n- Save it to localStorage\n- See all their saved prompts displayed on the page\n- Delete prompts they no longer need\n\nMake it look clean and professional with HTML, CSS, and JavaScript.\n```\n\nYour output will be different than mine (remember models are non-deterministic!) but depending on the model and provider, it may be very different than what I generated.\n\nOne thing you may notice when doing this is often your assistant will add additional features it wants to. It makes a lot of *assumptions* which introduces a lot more *randomness* than we want if we are going to use these models to generate code for us.\n\nSo, as an FYI, I deleted this scaffold for the project and will regenerate it in the next section.\n\nBut we can see these standard prompts already are pretty powerful! Now, let's add some technique to our prompts.\n","slug":"standard-prompt","title":"Standard Prompt","section":"Core Prompting Techniques","icon":"info-circle","filePath":"/home/runner/work/practical-prompt-engineering/practical-prompt-engineering/lessons/02-core-prompting-techniques/A-standard-prompt.md","nextSlug":"/practical-prompt-engineering/lessons/core-prompting-techniques/zero-shot","prevSlug":"/practical-prompt-engineering/lessons/introduction/temperature-top-p-tokens-and-context"}},"__N_SSG":true},"page":"/lessons/[section]/[slug]","query":{"section":"core-prompting-techniques","slug":"standard-prompt"},"buildId":"Su_DcT-hcs7Ah5fxh9Obs","assetPrefix":"/practical-prompt-engineering","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>